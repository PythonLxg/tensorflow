{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 保存模型的权重时，tf.keras 默认采用检查点格式。请传递 save_format='h5' 以使用 HDF5\n",
    "# g构造一个简单的全连接网络（多层感知机）\n",
    "model = keras.Sequential()  # 模型类型是层的堆叠\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # kernel_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # bias_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # activation=tf.softmax\n",
    "\n",
    "# 参数kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。默认为 \"Glorot uniform\" 初始化器。\n",
    "# 参数kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 构建模型\n",
    "model = keras.Sequential(\n",
    "[\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# optimizer：此对象会指定训练过程。从 tf.train 模块向其传递优化器实例，例如 tf.train.AdamOptimizer、tf.train.RMSPropOptimizer 或 tf.train.GradientDescentOptimizer。\n",
    "# loss：要在优化期间最小化的函数。常见选择包括均方误差 (mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。\n",
    "# metrics：用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象，常见有mae，accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 217us/step - loss: 11.5246 - acc: 0.0870 - val_loss: 11.7066 - val_acc: 0.0600\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.4701 - acc: 0.1070 - val_loss: 11.7025 - val_acc: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.4607 - acc: 0.1040 - val_loss: 11.7021 - val_acc: 0.0900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 11.4528 - acc: 0.1340 - val_loss: 11.6980 - val_acc: 0.0600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4477 - acc: 0.1370 - val_loss: 11.7025 - val_acc: 0.1000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.4434 - acc: 0.1500 - val_loss: 11.7050 - val_acc: 0.0500\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 11.4387 - acc: 0.1530 - val_loss: 11.7042 - val_acc: 0.1100\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 11.4358 - acc: 0.1500 - val_loss: 11.7089 - val_acc: 0.1100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.7574 - acc: 0.25 - 0s 33us/step - loss: 11.4298 - acc: 0.1730 - val_loss: 11.7055 - val_acc: 0.0900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.4251 - acc: 0.1690 - val_loss: 11.7073 - val_acc: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2526e73ce48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 训练模型\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 15us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.500132873535156, 0.091]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估模型\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：\n",
    "\n",
    "1 多输入模型，\n",
    "2 多输出模型，\n",
    "3 具有共享层的模型（同一层被调用多次），\n",
    "4 具有非序列数据流的模型（例如，剩余连接）。\n",
    "\n",
    "使用函数式 API 构建的模型具有以下特征：\n",
    "\n",
    "1 层实例可调用并返回张量。\n",
    "2 输入张量和输出张量用于定义 tf.keras.Model 实例。\n",
    "3 此模型的训练方式和 Sequential 模型一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, ))\n",
    "\n",
    "x = keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 212us/step - loss: 11.7386 - acc: 0.0970\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 11.5504 - acc: 0.0930\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 11.5003 - acc: 0.0840\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 11.4903 - acc: 0.1090\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 11.4817 - acc: 0.1240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2526c2d42e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "模型子类化\n",
    "通过对 tf.keras.Model 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。在 __init__ 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.dense_1 = keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - ETA: 4s - loss: 11.0811 - acc: 0.12 - 0s 187us/step - loss: 11.5214 - acc: 0.1100\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5132 - acc: 0.1120\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 11.5000 - acc: 0.1270\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.4928 - acc: 0.1150\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.4885 - acc: 0.1130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25204d7cdd8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化新模型类\n",
    "model = MyModel(num_classes=10)\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "自定义层\n",
    "通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层：\n",
    "\n",
    "build：创建层的权重。使用 add_weight 方法添加权重。\n",
    "call：定义前向传播。\n",
    "compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。\n",
    "或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用核矩阵实现输入 matmul 的自定义层\n",
    "class MyLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cld, config):\n",
    "        return cld(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 159us/step - loss: 11.4978 - acc: 0.0790\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.4897 - acc: 0.0960\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 11.4861 - acc: 0.0990\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.4851 - acc: 0.1070\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 11.4822 - acc: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25205155860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用自定义层创建模型\n",
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),\n",
    "    keras.layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "回调是传递给模型的对象，用于在训练期间自定义该模型并扩展其行为。您可以编写自定义回调，也可以使用包含以下方法的内置 tf.keras.callbacks：\n",
    "\n",
    "tf.keras.callbacks.ModelCheckpoint：定期保存模型的检查点。\n",
    "tf.keras.callbacks.LearningRateScheduler：动态更改学习速率。\n",
    "tf.keras.callbacks.EarlyStopping：在验证效果不再改进时中断训练。\n",
    "tf.keras.callbacks.TensorBoard：使用 TensorBoard 监控模型的行为。\n",
    "要使用 tf.keras.callbacks.Callback，请将其传递给模型的 fit 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "  32/1000 [..............................] - ETA: 5s - loss: 11.5129 - acc: 0.3438WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.180451). Check your callbacks.\n",
      "  64/1000 [>.............................] - ETA: 3s - loss: 11.1835 - acc: 0.2500WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.117833). Check your callbacks.\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 11.4762 - acc: 0.1270 - val_loss: 11.6970 - val_acc: 0.0300\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 1s 924us/step - loss: 11.4743 - acc: 0.1190 - val_loss: 11.6990 - val_acc: 0.1200\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 11.4727 - acc: 0.1180 - val_loss: 11.7112 - val_acc: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2520540fcc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x252065d3390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存和恢复\n",
    "# tf.keras.Model.save_weights 保存并加载模型的权重\n",
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "默认情况下，会以 TensorFlow 检查点文件格式保存模型的权重。权重也可以另存为 Keras HDF5 格式（Keras 多后端实现的默认格式\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_2\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_16\", \"trainable\": true, \"dtype\": null, \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_17\", \"trainable\": true, \"dtype\": null, \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.1.6-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型的配置，此操作会对模型架构（不含任何权重）进行序列化Keras 支持 JSON 和 YAML 序列化格式\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': None,\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_16',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': None,\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_17',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_2'},\n",
      " 'keras_version': '2.1.6-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: null\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_16\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: null\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_17\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_2\n",
      "keras_version: 2.1.6-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从 json 重新创建模型（刚刚初始化）\n",
    "fresh_model = tf.keras.models.model_from_json(json_string)\n",
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 子类化模型不可序列化，因为它们的架构由 call 方法正文中的 Python 代码定义。\n",
    "# 从 yaml 重新创建模型\n",
    "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 11.4854 - acc: 0.1050\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 11.4825 - acc: 0.1100\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 11.4819 - acc: 0.1100\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.4813 - acc: 0.1120\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 11.4809 - acc: 0.1230\n"
     ]
    }
   ],
   "source": [
    "# 整个模型可以保存到一个文件中，其中包含权重值、模型配置乃至优化器配置。这样，您就可以对模型设置检查点并稍后从完全相同的状态继续训练，而无需访问原始代码\n",
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "model.save('my_model.h5')\n",
    "\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\lxg\\AppData\\Local\\Temp\\tmpeml67p_3\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\lxg\\\\AppData\\\\Local\\\\Temp\\\\tmpeml67p_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F07084E0F0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "estimator = tf.keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
