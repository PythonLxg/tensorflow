{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 0阶\n",
    "mammal = tf.Variable('Elephant', tf.string)\n",
    "ignition = tf.Variable(451, tf.int16)\n",
    "floating = tf.Variable(3.14159265359, tf.float64)\n",
    "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)\n",
    "\n",
    "# 一阶\n",
    "mystr = tf.Variable(['Hello'], tf.string)\n",
    "cool_numbers = tf.Variable([3.123, 2.34575], tf.float32)\n",
    "first_primes = tf.Variable([2, 3, 4, 5, 7], tf.int32)\n",
    "its_very_coplicated = tf.Variable([12.3-4.86j, 7.5-6.4j], tf.complex64)\n",
    "\n",
    "# 二阶\n",
    "mymat = tf.Variable([[7],[11]], tf.int16)\n",
    "myxor = tf.Variable([[False, True],[True, False]], tf.bool)\n",
    "linear_squares = tf.Variable([[2], [4], [50], [88]], tf.int32)\n",
    "squarish_squares = tf.Variable([[4, 9],[16, 25]], tf.int32)\n",
    "mymatC = tf.Variable([[7],[11]], tf.int32)\n",
    "\n",
    "# 高阶\n",
    "my_image = tf.zeros([10, 299, 299, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Rank_2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 获取 tf.Tensor 对象的阶\n",
    "rank_of_squares = tf.rank(squarish_squares)\n",
    "print(rank_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 引用 tf.Tensor 切片,与pythonlist切片一样\n",
    "zeros = tf.zeros(squarish_squares.shape[1])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变形状\n",
    "rank_three_tensor = tf.ones([3, 4, 5])\n",
    "matrix = tf.reshape(rank_three_tensor, [6, 10])\n",
    "\n",
    "matrixB = tf.reshape(matrix, [3, -1])\n",
    "\n",
    "matrixAlt = tf.reshape(matrixB, [4, 3, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# 可以将 tf.Tensor 从一种数据类型转型为另一种（通过 tf.cast）\n",
    "float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)\n",
    "print(float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 9]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "constant = tf.constant([1, 2, 3])\n",
    "tensor = constant * constant\n",
    "print(sess.run(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "p = tf.placeholder(tf.float32)\n",
    "t = p + 1.0\n",
    "print(sess.run(t, {p: 2.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32_ref'>\n"
     ]
    }
   ],
   "source": [
    "# 创建变量\n",
    "# 创建变量的最佳方式是调用 tf.get_variable 函数。此函数要求您指定变量的名称。其他副本将使用此名称访问同一变量，以及在对模型设置检查点和导出模型时指定此变量的值。tf.get_variable 还允许您重复使用先前创建的同名变量，从而轻松定义重复利用层的模型。\n",
    "t_variable = tf.get_variable('myfloat_variable', [1, 2, 3])\n",
    "print(t_variable.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32_ref'>\n"
     ]
    }
   ],
   "source": [
    "my_variable = tf.get_variable('my_variable', [1, 2, 3],dtype=tf.int32)\n",
    "print(my_variable.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(my_variable.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 设备放置方式,将变量放置在特定设备上\n",
    "with tf.device('/device:GPU:1'):\n",
    "    c = tf.get_variable('v', [1])  # 创建了名为 v 的变量并将其放置在第二个 GPU 设备上"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 显式初始化变量在其他方面很有用。它允许您在从检查点重新加载模型时不用重新运行潜在资源消耗大的初始化器，并允许在分布式设置中共享随机初始化的变量时具有确定性\n",
    "sess.run(tf.global_variable_initializer())  # 在训练开始前一次性初始化所有可训练变量\n",
    "sess.run(my_variable.initializer)  # 自行初始化部分变量\n",
    "print(sess.run(tf.report_uninitialized_variables()))  # 打印所有尚未初始化的变量名称\n",
    "\n",
    "变量的初始值取决于另一变量的值,要指定变量的初始化顺序,最好使用variable.initialized_value()\n",
    "v = tf.get_variable('v, shape=(), initializer=tf.zeros_initializer())\n",
    "w = tf.get_variable('w', initializer=v.initialized_value() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为变量赋值\n",
    "v1 = tf.get_variable('vv', shape=(), initializer=tf.zeros_initializer())\n",
    "w1 = v1 + 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    assignment = v1.assign_add(1)  # 也可以使用assign\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取变量的值\n",
    "v = tf.get_variable('v2', shape=(), initializer=tf.zeros_initializer())\n",
    "assignment = v.assign_add(1)\n",
    "with tf.control_dependencies([assignment]):\n",
    "    w = v.read_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共享变量\n",
    "# 1 显式传递 tf.Variable 对象。\n",
    "# 2 将 tf.Variable 对象隐式封装在 tf.variable_scope 对象内\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    weights = tf.get_variable('weights', kernel_shape,\n",
    "                              initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable('biases', bias_shape,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "                        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在不同作用域内调用 conv_relu 可表明我们想要创建新变量\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope('conv1'):\n",
    "        relu1 = conv_relu(input_images, [5,5,32,32], [32])\n",
    "    with tf.variable_scope('conv2'):\n",
    "        return conv_relu(relu1, [5,5,32,32], [32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 reuse=True 创建具有相同名称的作用域\n",
    "with tf.variable_scope('model'):\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    output2 = my_image_filter(input2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 也可以调用 scope.reuse_variables() 以触发重用\n",
    "with tf.variable_scope('model') as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "    scope.reuse_variables()\n",
    "    output2 = my_image_filter(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 命名指令\n",
    "c_0 = tf.constant(0, name=\"c\")  # c\n",
    "\n",
    "c_1 = tf.constant(2, name=\"c\")  # c_1\n",
    "\n",
    "with tf.name_scope(\"outer\"):\n",
    "    c_2 = tf.constant(2, name=\"c\")  # outer/c\n",
    "\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_3 = tf.constant(3, name=\"c\")  # outer/inner/c\n",
    "\n",
    "    c_4 = tf.constant(4, name=\"c\")  # outer/c_1\n",
    "\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_5 = tf.constant(5, name=\"c\")  # outer/inner_1/c"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 在典型的分布式配置中部署 TensorFlow，您可以指定作业名称和任务 ID，以便将变量放到参数服务器作业 (\"/job:ps\") 中的任务上，\n",
    "# 并将其他操作放置到工作器作业 (\"/job:worker\") 中的任务上\n",
    "with tf.device(\"/job:ps/task:0\"):\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([784, 100]))\n",
    "    biases_1 = tf.Variable(tf.zeroes([100]))\n",
    "\n",
    "with tf.device(\"/job:ps/task:1\"):\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([100, 10]))\n",
    "    biases_2 = tf.Variable(tf.zeroes([10]))\n",
    "\n",
    "with tf.device(\"/job:worker\"):\n",
    "    layer_1 = tf.matmul(train_batch, weights_1) + biases_1\n",
    "    layer_2 = tf.matmul(train_batch, weights_2) + biases_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# tf.train.replica_device_setter API 可与 tf.device 结合使用，以针对数据并行分布式训练放置操作\n",
    "with tf.device(tf.train.replica_device_setter(ps_tasks=3)):\n",
    "    w_0 = tf.Variable(...)  # placed on \"/job:ps/task:0\"\n",
    "    b_0 = tf.Variable(...)  # placed on \"/job:ps/task:1\"\n",
    "    w_1 = tf.Variable(...)  # placed on \"/job:ps/task:2\"\n",
    "    b_1 = tf.Variable(...)  # placed on \"/job:ps/task:0\"\n",
    "\n",
    "    input_data = tf.placeholder(tf.float32)     # placed on \"/job:worker\"\n",
    "    layer_0 = tf.matmul(input_data, w_0) + b_0  # placed on \"/job:worker\"\n",
    "    layer_1 = tf.matmul(layer_0, w_1) + b_1     # placed on \"/job:worker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05393846 0.9460615 ]\n",
      " [0.10577406 0.8942259 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[37.0, -23.0],[1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(output))\n",
    "    \n",
    "    y_val, output_val = sess.run([y, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 9.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(3))\n",
    "y = tf.square(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, {x:[1.0, 2.0, 3.0]}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node {\n",
      "  name: \"MatMul_2/a\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\024B\\000\\000\\270\\301\\000\\000\\200?\\000\\000\\200@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_2/shape\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\002\\000\\000\\000\\002\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_2/RandomUniform\"\n",
      "  op: \"RandomUniform\"\n",
      "  input: \"random_uniform_2/shape\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed2\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul_2\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"MatMul_2/a\"\n",
      "  input: \"random_uniform_2/RandomUniform\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"_retval_MatMul_2_0_0\"\n",
      "  op: \"_Retval\"\n",
      "  input: \"MatMul_2\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"index\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 27\n",
      "}\n",
      "]\n",
      "dev_stats {\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  node_stats {\n",
      "    node_name: \"_SOURCE\"\n",
      "    all_start_micros: 1548405931152587\n",
      "    op_start_rel_micros: 2\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 10\n",
      "    timeline_label: \"_SOURCE = NoOp()\"\n",
      "    scheduled_micros: 17326173034585315\n",
      "    memory_stats {\n",
      "    }\n",
      "    all_start_nanos: 1548405931152587000\n",
      "    op_start_rel_nanos: 2600\n",
      "    op_end_rel_nanos: 3600\n",
      "    all_end_rel_nanos: 10800\n",
      "    scheduled_nanos: -1120571039124235744\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_2/a\"\n",
      "    all_start_micros: 1548405931155306\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 8\n",
      "    all_end_rel_micros: 41998\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 1733708609472\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_2/a = Const()\"\n",
      "    scheduled_micros: 17326173034705015\n",
      "    memory_stats {\n",
      "      persistent_memory_size: 16\n",
      "    }\n",
      "    all_start_nanos: 1548405931155306900\n",
      "    op_start_rel_nanos: 1000\n",
      "    op_end_rel_nanos: 7200\n",
      "    all_end_rel_nanos: 41998000\n",
      "    scheduled_nanos: -1120571039004535744\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_2/shape\"\n",
      "    all_start_micros: 1548405931197312\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 5\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_INT32\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 8\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 1733708608576\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_2/shape = Const()\"\n",
      "    scheduled_micros: 17326173079412115\n",
      "    memory_stats {\n",
      "      persistent_memory_size: 8\n",
      "    }\n",
      "    all_start_nanos: 1548405931197312100\n",
      "    op_start_rel_nanos: 1000\n",
      "    op_end_rel_nanos: 3600\n",
      "    all_end_rel_nanos: 5100\n",
      "    scheduled_nanos: -1120570994297435744\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_2/RandomUniform\"\n",
      "    all_start_micros: 1548405931197318\n",
      "    op_end_rel_micros: 11094\n",
      "    all_end_rel_micros: 11114\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1548405931208403\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "      allocation_records {\n",
      "        alloc_micros: 1548405931208455\n",
      "        alloc_bytes: -16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 1733655435456\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_2/RandomUniform = RandomUniform(random_uniform_2/shape)\"\n",
      "    scheduled_micros: 17326173079424415\n",
      "    memory_stats {\n",
      "    }\n",
      "    all_start_nanos: 1548405931197318800\n",
      "    op_end_rel_nanos: 11093800\n",
      "    all_end_rel_nanos: 11113900\n",
      "    scheduled_nanos: -1120570994285135744\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_2\"\n",
      "    all_start_micros: 1548405931208440\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 13\n",
      "    all_end_rel_micros: 16\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1548405931208444\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 1733655435136\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_2 = MatMul(MatMul_2/a, random_uniform_2/RandomUniform)\"\n",
      "    scheduled_micros: 17326173090539415\n",
      "    memory_stats {\n",
      "    }\n",
      "    all_start_nanos: 1548405931208440400\n",
      "    op_start_rel_nanos: 1000\n",
      "    op_end_rel_nanos: 13400\n",
      "    all_end_rel_nanos: 16500\n",
      "    scheduled_nanos: -1120570983170135744\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"_retval_MatMul_2_0_0\"\n",
      "    all_start_micros: 1548405931208459\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 5\n",
      "    timeline_label: \"_retval_MatMul_2_0_0 = _Retval(MatMul_2)\"\n",
      "    scheduled_micros: 17326173090564115\n",
      "    memory_stats {\n",
      "    }\n",
      "    all_start_nanos: 1548405931208459900\n",
      "    op_end_rel_nanos: 1100\n",
      "    all_end_rel_nanos: 4700\n",
      "    scheduled_nanos: -1120570983145435744\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf.Session.run 也接受可选的 options 参数（允许您指定与调用有关的选项）和可选的 run_metadata 参数（允许您收集与执行有关的元数据）。\n",
    "# 例如，您可以同时使用这些选项来收集与执行有关的跟踪信息\n",
    "\n",
    "y = tf.matmul([[37.0, -23.0],[1.0, 4.0]], tf.random_uniform([2, 2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    options = tf.RunOptions()\n",
    "    options.output_partition_graphs = True\n",
    "    options.trace_level = tf.RunOptions.FULL_TRACE\n",
    "    \n",
    "    metadata = tf.RunMetadata()\n",
    "    \n",
    "    sess.run(y, options=options, run_metadata=metadata)\n",
    "    print(metadata.partition_graphs)\n",
    "    print(metadata.step_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用多个图进行编程\n",
    "# 安装另一个 tf.Graph 作为默认图（使用 tf.Graph.as_default 上下文管理器）\n",
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "    c = tf.constant(\"Node in g_1\")\n",
    "    \n",
    "    sess_1 = tf.Session()\n",
    "    \n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "    d = tf.constant('Node in g_2')\n",
    "    \n",
    "sess_2 = tf.Session(graph=g_2)\n",
    "    \n",
    "assert c.graph is g_1\n",
    "assert sess_1.graph is g_1\n",
    "\n",
    "assert d.graph is g_2\n",
    "assert sess_2.graph is g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
